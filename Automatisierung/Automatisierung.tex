\documentclass[a4paper]{article}

\usepackage[a4paper,top=2cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{textcomp}
\usepackage[ngerman]{babel}
\usepackage{amsmath, amssymb}
\usepackage{accents}

% figure support
\usepackage{import}
\usepackage{xifthen}
\pdfminorversion=7
\usepackage{pdfpages}
\usepackage{transparent}
\newcommand{\incfig}[1]{%
    \def\svgwidth{\columnwidth}
    \import{./figures/}{#1.pdf_tex}
}

\pdfsuppresswarningpagegroup=1

\begin{document}

\section*{Wiederholung}
    \begin{itemize}
        \item x\ldots Eingang
        \item u \ldots Zusatnd
        \item y \ldots Ausgang
    \end{itemize}
Ein LTI-SISO-System ist definiert als
\[\dot x=A\cdot x + b\cdot u, x_0\]
\[y=c^{T} + d\xdot u\]
\[\implies x=V\dot z \ldots V \text{ist regulär}\]
\[\dot x = V \cdot \dot z = A\cdot V\cdot z + b\cdot u\]
\[\dot z = V^{-1}\cdot A\cdot V\cdot z + V^{-1}\cdot b\cdot u\]
\[y= c^{T}\cdot V\cdot z + d\cdot u\]
Bestimmung der Eigenwerte:
\[det(\lambda \cdot E - A)=0\]
\[det(V^{-1})\cdot det(\lambda \cdot E - A)\cdot det(V)=0\]
\[det(\lambda \cdot V^{-1}\cdot V - V^{-1}\cdot A\cdot V)=0\]
\[det(\lambda \cdot E - \tilde A)=0\]
\[\bold{det(V\cdot A)=det(V)\cdot det(A)}\]

Die Gleichungen sind äquivalent, die Dynamik des Systems bleibt unverändert.\newline
Die Nullstellen des charakterisitischen Polynoms werden als die "Wurzel des Polynoms" bezeichnet. Das liegt daran, dass die Nullstellen des Nennerpolynoms Polstellen und die des Zählerpolynoms Nullstellen genannt werden.
Die Eigenwerte charakterisieren die Dynamik, und diese wird sich nicht ändern, man wird nur mal anders draufschauen.\newline
Fallunterscheidungen der Eigenwerte im Rahmen dieser VO:
\begin{itemize}
    \item relle Eigenwerte
    \item konjugiert komplexe Eigenwerte
    \item Vielfachheiten (geom. und algebraisch)
        Die Geometrische Vielfachheit ist beschrieben, durch den Rangeinbruch der Matrix A. (Man setzt also einen Eigenwert in $det(\lambda E-A)$ ein, und schaut, wie weit der Rang zurückgeht; siehe Beispiel)
\end{itemize}

Warum brauchen wir Diagonalmatrizen? Es ist viel einfacher beim Lösen, die Eigenwerte spiegeln sich so in Exponentialfunktionen wieder. Die Lösungen von z und x lassen sich ineinander umrechnen.\newline
\section*{Wichtiges beispiel 3.1:}
\[\dot x = A \cdot x = 
\begin{pmatrix}
3 && 2 && -2\\
0 && 1 && 0\\
0 && 0 && 1\\
\end{pmatrix}\cdot x\]
Die Eigenwerte einer Dreiecksmatrix liegen IMMER auf der Diagonale. (wichtig für Prüfungen)
\[(A-\lambda_{i}\cdot E)\cdot v_i=0$, $i \in {1,2,3}\]
Für $\lambda_1=3$:
\[\implies v_{13}=0, v_{1,2}=0, v_{11}=beliebig\]
\[\begin{pmatrix} v_{11}\\ 0\\ 0\end{pmatrix}, v_{11}\neq 0\]
Für $\lambda_2=1$:
Durch einsetzen sieht man:
\[rang(A-1\cdot E)=1\]
$dim(Kern(A-1\cdot E))=3-rang(A-1\cdot E)=2$  \ldots der "Verlust" den man hat, ist immer die Dim des Kerns
analog wie zuvor ergibt sich:
\[2\cdot v_{21}+2\cdot v_{22}-2\cdot v_{23}=0\]
\[[-v_{22}+v_{23}, v_{22}, v_{23}]\]
Es können einige Variablen gewählt werden. Gewählt wurden
\[V=\begin{pmatrix} v_{1}&& v_{2}&& v_{3}\end{pmatrix}=\begin{pmatrix}
1 && 0 && -1\\
0 && 1 && 1\\
0 && 1 && 0\\
\end{pmatrix}\]
\[\dot z =V^{-1}\cdot A\cdot V\cdot z=\tilde A=\begin{pmatrix}
3 && 0 && 0\\
0 && 1 && 0\\
0 && 0 && 1\\
\end{pmatrix}\cdot z, z(9)=z_0=V^{-1}\cdot x_0\]
\[\tilde \Phi=\begin{pmatrix}
\exp(3t) && 0 && 0\\
0 && \exp(t) && 0\\
0 && 0 && \exp(t)\\
\end{pmatrix}\]

\section*{3.2.2 Notwendigkeit von Hauptvektoren}
$(A-\lambda \cdot E)v_1=$ wird gelöst, woraus dann die restlichen Hauptvektoren bestimmt werden können:
\[(A-\lambda E)v_{j+1}=v\]

Nach Herleitung wie im Skriptum folgt:
\[A\cdot V=v\cdot (\lambda\cdot E+N)\]
 Beispiel:  Berechne $V\cdot N$, wobei $V \in R^{n x n}$
N ist eine nilpotente Matrix, die wie ein Schieberegister funktioniert, sie verschiebt alle Spaltenvektoren um eine Stelle nach rechts. Nach genügend vielen Schritten kommt immer eine Nullmatrix raus!
\newline
Wenn gilt $A\cdot B=B\cdot A$, dann gilt $\exp(A+B)=\exp(A)\exp(B)$. Damit folgt aus 3.24 die Lösung 2.25.
Was sehen wir: Das Lösungsverhalten wird durch den Eigenwert dominiert. Hiermit wurde das Lösungsverhalten gezeigt, wenn die algebraische Vielfachheit größer als die geometrische ist.

Keine Ahnung was das hier werden soll:
 \[
\begin{pmatrix}
    v_{11,R}+I\cdot v_{11,R} && v_{12,R}+I\cdot v_{12,R}\\
v_{11,R}-I\cdot v_{11,R} && v_{12,R}-I\cdot v_{12,R}\\
\end{pmatrix}  
\cdot \frac{1}{2}\cdot
\begin{pmatrix}
1 && 1\\
-I && I
\end{pmatrix} =
\begin{pmatrix}
v_{11,R} && v_{12,R}\\
v_{11,I} && v_{12,I}
\end{pmatrix} 
\]

 \subsection*{3.irgendwas Zusammenfassung}
 Man betrachte wieder die Fallunterscheidung der Eigenwerte. Die Eigenwerte bestimmen nämlich das Lösungsverhalten.\newline

Beispiel: Unbedingt selbstständig durchrechnen (er hat das Beispiel nur durchbesprochen)

Mit der Dynamikmatrix, im speziellen mit ihrer Eigenwerte, identifizieren wir das Verhalten. Im Weiteren wird die Stabilität beurteilt. Wir haben heute die Fallunterscheidungen der Eigenwerte untersucht, weil uns die Lage der Eigenwerte extrem viel sagen.
\section*{3.3 Allgemeines Lösungsverhalten}
Ein lineares System kann nicht, in endlicher Zeit nach unendlich oder gegen 0 gehen. Ein nichtlineares System kann das. Siehe Satz 3.3. Mit Satz 3.4 haben wir den ersten Stabilitätsbegriff kennengelernt.

\section*{Nächstes Mal:}
Was ist die Bedeutung des Eigenvektors. Im Beispiel der Flugtechnik ist weiters die Richtung notwendig, da wird der EigenVEKTOR notwendig.

\section*{31.10.2023}
\section*{Wiederholung}
\section*{3.5 Realisierungsproblem}
Gegeben sei ein LTI-System:
\[ \dot x = Ax+bu\text{,}x_{0} \]
\[ dot y = c^{T}x+du \]
Daraus kann mit einem Ausgangszustand $x_{0}$ eine Übertragungsfunktion im Laplacebereich hergeleitet werden:
\[ G(s)=\frac{\hat{Y(s)}}{\hat{U}(s)}=c^{T}(SE-A)^{-1b+d}\]
Der reverse Weg beschreibt ein Realisierungsproblem.

Wenn der Zählergrad grösser als der Nennergrad ist, hat man einen DIfferenzierer, daher macht es Sinn, dass man da keinen Zustand haben kann.
Es werden Eigenschaften mit den englischen Begriffen
\begin{itemize}
    \item proper: Zählergrad \ge  Nenner
    \item strictly proper: Zählergrad > Nennergrad
\end{itemize}

\subsubsection*{Beispiel:}
\[ \tilde{b_{l}}=b_{l}-a_{l}b_{n} \]
\ldots bitte nachlesen

\subsection*{Stabilität}

\subsubsection*{BIBO-Stabilität}
\[ \dot x=Ax\text{,} x_{0} \]
\[ G_{s}=\frac{\hat{Y}}{\hat{U}}\]
\[ \lim_{t \to \infty} x(t)=0 \]
\subsubsection*{Satz 3.7: BIBO-Stabilität anhand der Impulsantwort}
Impuls-Eingang Laplace-transformiert ergibt
\[ G(s)=1\]
daraus folgt
\[ \hat{Y}(s)=G(s)*1\text{,}y(t)=\mathbb{L}^{-1}\{G(s)\}=g(t) \]

\subsubsection*{Satz 3.8: BIBO-Stabilität anhand der Impulsantwort}
\[ G(s)=\frac{\hat{Y}}{\hat{U}}=c^{T}(SE-A)^{-1}b+d=\frac{Z(s)}{N(s)} \]
Hieraus lässt sich erkennen, dass sich die Eigenwerte im Nenner befinden müssen.

\section*{3.7 Kontinuierlicher Frequenzgang}
Wir beschränken uns auf Harmonische Eingangs- und Ausgangsgrössen. Wenn eine 
harmonische Grösse aufgeschaltet wird, schwingen nach ausreichend langer Zeit
alle transienten Funktionen im Ausgang ab und es bleibt eine harmonische
Schwingung mit der gleichen Frequenz.

\subsubsection*{Beispiel 3.4} Im Skriptum durchbesprochen
Man sieht, wir erhalten wieder eine harmonische Schwingung, es ändern sich nur 
Amplitude und Phase. Am Beispiel $Y=U^{2}$ sieht man auch direkt, dass das nur
für lineare Systeme gilt.

Rückblick auf die komplexen Zahlen: $z_{1}=a_{1}+Ib_{1}=Betrag(z_{1})\cdot e^{Iarg(z_{1})}$ 
\[ Betrag(z_{1})=\sqrt{a_{1}^{2}+b_{1}^{2}}  \]
\[ arg(z_{1}) =\arctan(\frac{b_{1}}{a_{1}})\]
Für die Prüfung: $\arctan(\frac{1}{1})\neq \arctan(-\frac{1}{-1})$ das ist KEIN
Rechenfehler, das wird bei der Prüfung als ein normaler Fehler angerechnet.\newline
HÜ: Rechne auch $z_{1}\cdot z_{2}$ und $\frac{z_{1}}{z_{2}}$ aus.
Der Prof hat lang und breit erklärt, dass wir bei der Prüfung nachdenken müssen,
es werden keine 40 Zeilen zum umformen erwartet. Das dividieren zweier komplexer
Zahlen ist kein Trick sondern eine Grundlage.

Beim Aufbau eines Frequenzgangs könnte man eine Frequenz einstellen, und aufs
Einschwingen warten, und das für ganz viele Frequenzen wiederholen. Wird aber
in der Praxis nicht so gemacht. Professionell wird Eingang und Ausgang
irgendwie bestimmt angeregt, beides FF-transformiert und die beiden FFTs mit-
einander dividiert.

Zur Darstellung werden Bodediagram und Ortskurve verwendet.

Eine Nyquist-Ortskurve wird mit Betrag und Winkel geplottet (siehe Skriptum)

Das Bodediagram:
\begin{itemize}
    \item Amplitudengang: doppellogarithmisch aufgetragener Betrag
    \item Phasengang
\end{itemize}

Wieso wird das so gemacht? Siehe Gleichungen 3.117 und 3.118
\[ \log(\frac{a}{b})=\log(a)-\log(b) \]
\[ \log(a\cdot b)=\log(a)+\log(b) \]

Zu Gleichung 3.119:
Es sind einige Erkenntnisse zu den reellen und konj. kompl. Nullstellen zu sehen.
Weiters:
\begin{itemize}
    \item $\xi=0$ \implies  $1+(\frac{s}{\omega_{z}^{2}}=0$ 
    \item $\xi=1$ \implies  $ 1+ 2(\frac{s}{\omega_{z}+(\frac{s}{\omega_{z}})^2=(1+\frac{s}{\omega_{z}})^{2}=0}$
\end{itemize}
Die Nullstellen lassen sich sehr gut in der komplexen Ebene abbilden.
Diese Erkenntnis ist sehr fundamental für die gesamte Vorlesung.

$V$ wird als Verstärkungsfaktor bezeichnet.

\[ G(s)=\frac{\hat{Y}}{\hat{U}} \]
\[ u(t)=\sigma(t) \text{laplacetransformiert} \hat{U}=\frac{1}{s}\]
\[ \sigma(t) \text{\ldots Heavyside-Funktion} \]
\[ \hat{Y}=G(s)\hat{U}=G(s) \frac{1}{s} \]
Endwertsatz: $\lim_{t \to \infty} y(t)=\lim_{s \to 0} s \hat{y}=\lim_{s \to 0} G(s)=G(0)=V \frac{Z(0)}{N(0)}=V$ 

$(I\omega)'$ wird als Integrator/Differenzierer bezeichnet.
Integrator
\[ \dot x=u \text{,} x_{0}=0\]
\[ y=x \]
\[ s \hat{x}=\hat{u} \]
\[ \hat{y}=\hat{x} = \frac{\hat{u}}{s} \implies \frac{\hat{y}}{\hat{u}}=\frac{1}{s}\]

Differenzierer
\[ y=\dot u \]
\[ \hat{y}=s \hat{u} \]
\[ \frac{\hat{y}}{u}=s=G(s) \]

\[ G(s)=\frac{1}{s}=\frac{1}{I\omega}\]
\[ Betrag(G(s))_{dB}= \text{Im Bodediagram plotten (Gerade mit k=-45°)}\]
\[ arg(\frac{1}{I\omega})=0-arg(I\omega)=-90° \text{\ldots const}\]


\[ G(s)=\frac{1}{s^{2}}=-\frac{1}{\omega^{2}}\]
\[ Betrag(G(s))_{dB}= \text{Im Bodediagram plotten}\]
\[ arg(\frac{1}{s^{2}})=\ldots \]

Der Differenzierer steigt stattdessen. Für sehr hohe Frequenzen geht der Differenzierer gegen unendlich.
Da jedes reale System Rauschen hat, macht es den Differenzierer sehr unangenehm.
Der Differenzier macht in echt einfach keinen Sinn, und MatLab weigert sich, ihn aus der Toolbox zu entfernen.

\end{document}
